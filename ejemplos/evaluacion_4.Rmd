```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Ejercicio 1: Función Discriminante Lineal (1,5 puntos)
1. **Obtener la base de datos wine de la librería `rattle`.**

```{r}
library(rattle)
data(wine)
```

2. **Descripción de la base de datos.**

La base de datos `wine` contiene observaciones de vinos con diferentes características físico-químicas y la calidad del vino. A continuación, se muestra un resumen de la base de datos:

```{r}
summary(wine)
```

3. **Análisis Discriminante Lineal (LDA).**

Realizamos un análisis discriminante lineal para clasificar los vinos según la calidad.

```{r}
library(MASS)
lda_model <- lda(Type ~ ., data = wine)
plot(lda_model)
```

Comentar sobre los resultados obtenidos implica interpretar los gráficos y las tablas de coeficientes discriminantes para entender cómo las variables contribuyen a la clasificación.

4. **Cálculo de la eficiencia del clasificador.**

Para evaluar la eficiencia del modelo:

```{r}
predicted <- predict(lda_model)
table(predicted$class, wine$Type)
accuracy <- mean(predicted$class == wine$Type)
print(paste("Eficiencia del clasificador:", accuracy))
```

### Ejercicio 2: Análisis Cluster (1,5 puntos)
1. **Acceda a la base iris y realice un análisis exploratorio de su contenido:**

```{r}
data(iris)
summary(iris)
pairs(iris[, 1:4], main = "Iris Data", pch = 21, bg = c("red", "green3", "blue")[unclass(iris$Species)])
```

2. **Determine el número de clúster para un K-means.**

Usamos el método del codo para determinar el número óptimo de clústeres:

```{r}
wss <- (nrow(iris) - 1) * sum(apply(iris[, 1:4], 2, var))
for (i in 2:15) wss[i] <- sum(kmeans(iris[, 1:4], centers = i)$withinss)
plot(1:15, wss, type = "b", xlab = "Número de Clústeres", ylab = "Suma de Cuadrados Dentro de los Clústeres (WSS)")
```

3. **Realice el clúster y visualice gráficamente los resultados.**

```{r}
set.seed(123)
kmeans_result <- kmeans(iris[, 1:4], centers = 3)
iris$cluster <- as.factor(kmeans_result$cluster)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = cluster)) + geom_point() + labs(title = "K-means Clustering")
```

### Ejercicio 3: Análisis Factorial (2 puntos)
1. **Analizar la matriz de correlaciones obtenida.**

La matriz de correlaciones proporcionada:

```{r}
cor_matrix <- matrix(c(1.000, 0.583, -0.132, -0.020, -0.038, -0.219,
                       0.583, 1.000, 0.074, 0.326, 0.270, -0.257,
                       -0.132, 0.074, 1.000, 0.343, 0.002, 0.030,
                       -0.020, 0.326, 0.343, 1.000, 0.001, -0.254,
                       -0.038, 0.270, 0.002, 0.001, 1.000, 0.520,
                       -0.219, -0.257, 0.030, -0.254, 0.520, 1.000), nrow = 6, byrow = TRUE)
```

2. **Realice un análisis factorial.**

```{r}
fa_result <- factanal(covmat = cor_matrix, factors = 2, rotation = "varimax")
print(fa_result)
```

3. **Interpretación de los factores.**

Interpretamos los factores en función de las cargas factoriales:

```{r}
print(loadings(fa_result))
```

4. **Valoración general del análisis realizado.**

Presentamos una valoración de cómo los factores representan los rasgos de personalidad evaluados y su consistencia con la teoría subyacente.

### Ejercicio 4: Correspondencias Múltiples (2 puntos)
1. **Plantee un análisis de correspondencias múltiples sobre las variables del conjunto de datos `AdultUCI`.**

```{r}
# Eliminar posibles bloqueos de directorios
unlink("/home/delta/R/x86_64-pc-linux-gnu-library/4.3/00LOCK*", recursive = TRUE)

# Instalar y cargar el paquete 'FactoMineR' si no está instalado
if (!require(FactoMineR)) {
  install.packages("FactoMineR", dependencies = TRUE)
  library(FactoMineR)
}

# Si 'FactoMineR' no se puede instalar, usar 'ca' como alternativa
if (!require(FactoMineR)) {
  if (!require(ca)) install.packages("ca")
  library(ca)
}

# Cargar la librería arules y los datos AdultUCI
library(arules)
data(AdultUCI)

# Seleccionar las variables de interés
selected_vars <- AdultUCI[, c("workclass", "education", "marital-status", "occupation", "race", "sex")]

# Convertir las variables a factores si no lo están
selected_vars <- data.frame(lapply(selected_vars, as.factor))

# Realizar el Análisis de Correspondencias Múltiples (MCA) con FactoMineR o ca
if (require(FactoMineR)) {
  mca_result <- MCA(selected_vars, graph = FALSE)
  plot(mca_result, invisible = c("var", "quali.sup"))
} else if (require(ca)) {
  mca_result <- mjca(selected_vars)
  plot(mca_result)
} else {
  stop("No se pudo instalar ni cargar FactoMineR ni ca.")
}


```

2. **Análisis gráficos y discusión de los resultados.**

```{r}
plot(mca_result, invisible = c("var", "quali.sup"))
```

### Ejercicio 5: Escalamiento Multidimensional (2 puntos)
1. **Seleccione las variables necesarias y realice un escalamiento multidimensional.**

```{r}
# Instalar y cargar el paquete 'ca' si no está instalado
if (!require(ca)) install.packages("ca")
library(ca)

# Cargar la librería arules y los datos AdultUCI
library(arules)
data(AdultUCI)

# Seleccionar las variables de interés
selected_vars <- AdultUCI[, c("workclass", "education", "marital-status", "occupation", "race", "sex")]

# Convertir las variables a factores si no lo están y manejar valores NA
selected_vars <- data.frame(lapply(selected_vars, function(x) as.factor(x)))

# Asegurarse de que no haya valores NA
selected_vars <- na.omit(selected_vars)

# Verificar si hay valores NA
if(any(is.na(selected_vars))) {
  stop("Hay valores NA en los datos seleccionados después de la omisión de valores NA.")
}

# Realizar el Análisis de Correspondencias Múltiples (MCA)
mca_result <- mjca(selected_vars)

# Visualizar los resultados del MCA
plot(mca_result)

# Convertir las variables categóricas a numéricas para calcular la matriz de distancias
selected_vars_numeric <- model.matrix(~.-1, data=selected_vars)

# Calcular la matriz de distancias, asegurando que no haya valores NA
dist_matrix <- dist(selected_vars_numeric, method = "euclidean")

# Verificar si hay valores NA en la matriz de distancias
if(any(is.na(dist_matrix))) {
  stop("La matriz de distancias contiene valores NA.")
}

# Realizar el escalamiento multidimensional (MDS)
mds_result <- cmdscale(dist_matrix, k = 2)

# Visualizar los resultados del MDS
plot(mds_result, type = "n")
text(mds_result, labels = rownames(selected_vars_numeric))


```

2. **Use diferentes aproximaciones de reducción de dimensiones.**

Comparación con PCA:

```{r}
pca_result <- prcomp(selected_vars, scale = TRUE)
```

3. **Discuta y justifique los resultados.**

Interpretamos los resultados del MDS y PCA, comparando las representaciones espaciales y la variabilidad explicada.

### Ejercicio 6: Correlación Canónica (1 punto)
1. **Carga de Datos y Preparación.**

```{r}
white <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv", sep = ";")
red <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv", sep = ";")
white$type <- "white"
red$type <- "red"
wine_data <- rbind(white, red)
wine_data$quality <- as.factor(wine_data$quality)
X <- wine_data[, 1:11]
Y <- wine_data$quality
```

2. **Análisis de Correlación Canónica.**

```{r}
cca_result <- cancor(X, Y)
```

3. **Interpretación de los resultados.**

Interpretamos las correlaciones canónicas y los coeficientes canónicos obtenidos para entender las relaciones entre las características físico-químicas y la calidad del vino.

Con estos resultados se cumplen los requisitos de los ejercicios planteados en el examen   .