---
title: "Evaluacion1"
author: "Danie Carrera Bonilla"
date: "2025-03-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Evaluacion 1

## PREPROCESADO DE DATOS

### 0. Carga del dataset
```{r}
options(repos = "https://cran.r-project.org")

install.packages(c("arrow", "dplyr", "ggplot2", "tidyr", "corrplot", "isotree"))

```

```{r}
library(arrow)
library(dplyr)
library(ggplot2)
library(tidyr)
library(corrplot)
set.seed(123)
```



## 1. ANÁLISIS DESCRIPTIVO Y GRÁFICO (UNIVARIANTE Y BIVARIANTE)
 
### 1.1 Resumen de variables y nulos
```{r}
# Leer los datos desde la tabla

df <- read_parquet("parkinsons_disease_data.parquet")
# Verificar que se haya cargado correctamente
head(df)
```
En este paso inicial del análisis, se ha realizado la carga del dataset parkinsons_disease_data.parquet para verificar que los datos se hayan cargado correctamente en el entorno de trabajo. Para ello, se utilizó la  función read_parquet(), que permite la lectura de archivos en formato Parquet, un formato optimizado para el almacenamiento y procesamiento de datos.

# 1.2 Análisis univariante para variables numéricas

```{r}

numeric_vars <- c("Age", "BMI", "AlcoholConsumption", "PhysicalActivity",
                  "DietQuality", "SleepQuality", "SystolicBP", "DiastolicBP",
                  "CholesterolTotal", "CholesterolLDL", "CholesterolHDL",
                  "CholesterolTriglycerides", "MoCA", "FunctionalAssessment")

for (v in numeric_vars) {
  p <- ggplot(df, aes_string(x = v)) +
         geom_histogram(bins = 30, fill = "skyblue", color = "black") +
         ggtitle(paste("Histograma de", v))
  print(p)
}
```

Se han generado histogramas para analizar la distribución de varias variables numéricas del conjunto de datos. A continuación, se presentan algunas observaciones clave:

FunctionalAssessment: Se observa una distribución relativamente uniforme, sin una clara concentración en valores específicos. Esto sugiere que los niveles de funcionalidad en los pacientes están repartidos de manera equitativa, sin una tendencia dominante.

MoCA (Evaluación Cognitiva de Montreal): La distribución muestra una dispersión considerable, lo que indica variabilidad en el estado cognitivo de los pacientes. La presencia de valores bajos y altos sugiere que algunos pacientes tienen deterioro cognitivo significativo, mientras que otros mantienen un desempeño normal.

CholesterolTriglycerides: Se nota una amplia variabilidad en los niveles de triglicéridos, sin una distribución normal aparente. Este comportamiento es esperable, dado que los niveles de triglicéridos pueden verse afectados por múltiples factores como la dieta y la genética.

CholesterolHDL y CholesterolTotal: Ambas variables presentan una distribución heterogénea, con una dispersión que indica diferentes perfiles lipídicos entre los pacientes. La presencia de valores extremos puede indicar pacientes con alto riesgo cardiovascular.

### 1.3 Boxplots univariantes

```{r}

for (v in numeric_vars) {
  bp <- ggplot(df, aes_string(y = v)) +
          geom_boxplot(fill = "lightgreen") +
          ggtitle(paste("Boxplot de", v))
  print(bp)
}

```

El análisis de los boxplots univariantes nos permite visualizar la distribución de cada variable numérica y detectar la presencia de valores atípicos. En los gráficos generados se observa lo siguiente:

Distribución de las variables: Los boxplots nos muestran la mediana (línea central dentro de la caja), los cuartiles (caja) y el rango intercuartílico (bigotes). En general, los valores parecen estar distribuidos de manera amplia, lo que sugiere una considerable variabilidad entre los pacientes.

Posibles valores atípicos: Aunque en estos gráficos no se observan puntos fuera de los bigotes, la amplitud de las cajas en algunas variables como CholesterolTriglycerides o MoCA sugiere que puede haber datos extremos que deberán ser analizados con más detalle.

Variabilidad entre métricas clínicas: En variables como FunctionalAssessment, se observa una distribución bastante homogénea, mientras que en MoCA (prueba cognitiva) hay mayor dispersión, lo que podría indicar diferencias en el impacto de la enfermedad sobre la cognición de los pacientes.


### 1.4 Análisis bivariante: Ejemplo de tabla cruzada entre Diagnosis y Gender

```{r}
tabla_diag_gender <- table(df$Gender, df$Diagnosis)
print(tabla_diag_gender)
```
En este análisis, se ha generado una tabla cruzada para examinar la relación entre el género de los pacientes y el diagnóstico de la enfermedad de Parkinson. Los valores obtenidos son:

Hombres (0):

373 pacientes no diagnosticados con Parkinson.
587 pacientes diagnosticados con Parkinson.
Mujeres (1):

351 pacientes no diagnosticados con Parkinson.
589 pacientes diagnosticados con Parkinson.
Interpretación:
Se observa que la distribución de la enfermedad es bastante similar entre hombres y mujeres.
La cantidad de pacientes diagnosticados con Parkinson es mayor que la cantidad de no diagnosticados en ambos géneros.
No se aprecia una diferencia significativa en la proporción de afectados por género, pero sería necesario un análisis estadístico (como una prueba de chi-cuadrado) para determinar si la diferencia es significativa.
Este resultado sugiere que la enfermedad de Parkinson podría afectar a hombres y mujeres de manera relativamente equitativa en esta muestra, aunque sería interesante contrastarlo con otros estudios para verificar si hay una mayor predisposición en algún género.
### 1.5 Análisis de correlación entre variables numéricas

```{r}

num_df <- df %>% select(all_of(numeric_vars)) %>% drop_na()
corr_matrix <- cor(num_df)
corrplot(corr_matrix, method = "circle")
```

Se ha realizado un análisis de correlación entre las variables numéricas del conjunto de datos utilizando una matriz de correlación visualizada mediante un gráfico de círculos.

Interpretación de la matriz de correlación:
Valores positivos (círculos oscuros y azules) indican que las variables están positivamente correlacionadas, es decir, cuando una aumenta, la otra también tiende a aumentar.
Valores negativos (círculos oscuros y rojos, que aquí no parecen presentes) indicarían relaciones inversas, donde una variable aumenta mientras la otra disminuye.
Valores cercanos a 0 sugieren que no hay una relación lineal fuerte entre las variables.
Observaciones clave:
Hay correlaciones esperadas entre ciertas variables, como la relación entre SystolicBP y DiastolicBP, lo cual es lógico ya que ambas están relacionadas con la presión arterial.
Los diferentes tipos de colesterol (Total, LDL, HDL y Triglycerides) también muestran una fuerte correlación entre sí, lo cual es esperable en datos de salud.
MoCA y FunctionalAssessment, que miden evaluación cognitiva y funcional, podrían presentar algún grado de correlación, lo cual tendría sentido clínico.

## 2. REVISIÓN DE POSIBLES VALORES ATÍPICOS

### 2.1 Métodos univariantes: Boxplots ya generados en 1.3
```{r}
library(isotree)

vars_outlier <- c("Age", "BMI", "SystolicBP", "DiastolicBP", "CholesterolTotal", 
                  "MoCA", "FunctionalAssessment")

# Seleccionar variables relevantes y eliminar valores nulos
df_outlier <- df %>% select(all_of(vars_outlier)) %>% drop_na()

# Entrenar modelo Isolation Forest
iso_model <- isolation.forest(df_outlier, ntrees = 100)

# Obtener puntajes de anomalías
df_outlier$outlier_score <- predict(iso_model, df_outlier)

# Umbral para definir valores atípicos
threshold <- 0.6

# Etiquetar outliers
df_outlier$outlier_label <- ifelse(df_outlier$outlier_score > threshold, "Outlier", "Normal")

# Mostrar la tabla de clasificación
print(table(df_outlier$outlier_label))


```
En este ejercicio, se ha utilizado el modelo Isolation Forest para detectar valores atípicos en las variables seleccionadas. Isolation Forest es un algoritmo basado en árboles que identifica anomalías al medir qué tan rápido una observación se aísla del resto.

Proceso realizado:
Selección de variables: Se eligieron variables relevantes como edad, IMC, presión arterial y niveles de colesterol, entre otros.
Limpieza de datos: Se eliminaron valores nulos para evitar problemas en el entrenamiento del modelo.
Entrenamiento de Isolation Forest: Se generaron 100 árboles (ntrees = 100) para estimar el grado de anomalía de cada observación.
Predicción de puntuaciones: El modelo asignó un puntaje de anormalidad a cada dato.
Definición de umbral: Se estableció un threshold de 0.6, donde los valores superiores a este umbral se consideraron "Outliers".
Clasificación de datos: Se etiquetaron los datos como "Normal" o "Outlier".
Resumen de resultados: De un total de 1915 observaciones, solo 1 fue identificada como outlier, lo que indica que la mayoría de los datos no presentan anomalías significativas según este modelo.

El modelo no ha detectado una cantidad significativa de valores atípicos, lo que sugiere que los datos analizados no contienen muchas observaciones extremas o que el umbral de detección es muy alto. Para mejorar el análisis, se podría ajustar el threshold o evaluar la distribución de las puntuaciones de anomalía.

## 3. IMPUTACIÓN DE DATOS AUSENTES

### 3.1 Imputación en variables numéricas (usando la mediana)
```{r}

impute_median <- function(x) {
  x[is.na(x)] <- median(x, na.rm = TRUE)
  x
}
df <- df %>%
  mutate(
    Age = impute_median(Age),
    BMI = impute_median(BMI),
    AlcoholConsumption = impute_median(AlcoholConsumption),
    PhysicalActivity = impute_median(PhysicalActivity),
    DietQuality = impute_median(DietQuality),
    SleepQuality = impute_median(SleepQuality),
    SystolicBP = impute_median(SystolicBP),
    DiastolicBP = impute_median(DiastolicBP),
    CholesterolTotal = impute_median(CholesterolTotal),
    CholesterolLDL = impute_median(CholesterolLDL),
    CholesterolHDL = impute_median(CholesterolHDL),
    CholesterolTriglycerides = impute_median(CholesterolTriglycerides),
    MoCA = impute_median(MoCA),
    FunctionalAssessment = impute_median(FunctionalAssessment)
  )

```


### 3.2 Imputación en variables categóricas (usando el modo)

```{r}

impute_mode <- function(x) {
  ux <- unique(x[!is.na(x)])
  mode_val <- ux[which.max(tabulate(match(x, ux)))]
  x[is.na(x)] <- mode_val
  x
}
df <- df %>%
  mutate(
    Gender = impute_mode(Gender),
    Ethnicity = impute_mode(Ethnicity),
    EducationLevel = impute_mode(EducationLevel),
    Smoking = impute_mode(Smoking),
    FamilyHistoryParkinsons = impute_mode(FamilyHistoryParkinsons),
    TraumaticBrainInjury = impute_mode(TraumaticBrainInjury),
    Hypertension = impute_mode(Hypertension),
    Diabetes = impute_mode(Diabetes),
    Depression = impute_mode(Depression),
    Stroke = impute_mode(Stroke),
    Tremor = impute_mode(Tremor),
    Rigidity = impute_mode(Rigidity),
    Bradykinesia = impute_mode(Bradykinesia),
    PosturalInstability = impute_mode(PosturalInstability),
    SpeechProblems = impute_mode(SpeechProblems),
    SleepDisorders = impute_mode(SleepDisorders),
    Constipation = impute_mode(Constipation),
    Diagnosis = impute_mode(Diagnosis)
  )

# Verificar que no queden NA
sapply(df, function(x) sum(is.na(x)))
```
En este paso del análisis, el objetivo fue manejar los valores faltantes en el conjunto de datos utilizando diferentes estrategias de imputación.

Proceso realizado:
Imputación por moda (impute_mode): Se utilizó para variables categóricas como Género, Nivel de educación, Hipertensión, Diabetes, Rigidez, etc.. La moda es el valor más frecuente en la variable, por lo que es una buena opción cuando hay categorías dominantes.

Error en Bradykinesia: En la línea de código, hubo un intento de usar impute_median(x), lo que sugiere un error tipográfico. En este caso, debería usarse impute_mode(Bradykinesia), manteniendo consistencia con las otras variables categóricas.

Verificación de valores faltantes: Se aplicó sapply(df, function(x) sum(is.na(x))) para comprobar que todas las columnas quedaron sin valores NA, lo que confirma que la imputación se realizó correctamente.

Conclusión:
El tratamiento de valores faltantes es crucial para evitar sesgos en los análisis y modelos predictivos. Usar la moda para variables categóricas es una decisión acertada, ya que preserva la estructura de los datos. Sin embargo, es importante corregir el error en Bradykinesia para asegurar la correcta imputación.

## 4. EQUILIBRADO DE LA MUESTRA SOBRE Diagnosis

### 4.1 Conteo inicial de Diagnosis

```{r}
print(table(df$Diagnosis))

```
En este paso, se ha realizado un conteo de la variable Diagnosis, que indica la distribución de los casos en el conjunto de datos.

Resultados obtenidos:
801 registros con Diagnosis = 0 → Representa los individuos que no tienen la enfermedad.
1304 registros con Diagnosis = 1 → Representa los individuos que sí tienen la enfermedad.
Interpretación:
El conjunto de datos presenta un desequilibrio de clases, donde hay más casos positivos (Diagnosis = 1) que negativos (Diagnosis = 0). Esto es relevante porque en modelos de clasificación, un desbalance puede afectar el rendimiento del modelo, haciendo que favorezca la clase mayoritaria. En pasos posteriores, podría considerarse balancear los datos mediante técnicas como undersampling o oversampling para mejorar el desempeño del modelo.

### 4.2 Reducción de la clase mayoritaria (undersampling)

```{r}
library(dplyr)

df_diag0 <- df %>% filter(Diagnosis == 0)
df_diag1 <- df %>% filter(Diagnosis == 1)

# Verificamos que ambas clases tienen datos
if (nrow(df_diag0) > 0 & nrow(df_diag1) > 0) {
  
  if (nrow(df_diag0) > nrow(df_diag1)) {
    df_diag0_bal <- df_diag0 %>% slice_sample(n = nrow(df_diag1))
    df_balanced <- bind_rows(df_diag0_bal, df_diag1)
  } else {
    df_diag1_bal <- df_diag1 %>% slice_sample(n = nrow(df_diag0))
    df_balanced <- bind_rows(df_diag0, df_diag1_bal)
  }
  
  print("Muestra equilibrada creada correctamente")
} else {
  print("Error: Al menos una de las clases tiene 0 observaciones")
}


```

### 4.3 Verificar el balance final

```{r}
print(table(df_balanced$Diagnosis))

```
Objetivo del procedimiento
Se ha aplicado un undersampling para equilibrar la cantidad de registros en cada clase de la variable Diagnosis. Dado que inicialmente había 1304 casos positivos y 801 casos negativos, era necesario reducir la cantidad de la clase mayoritaria para evitar que domine el análisis.

Procedimiento
Filtración de clases: Se separaron los registros en dos subconjuntos:

df_diag0: Casos con Diagnosis = 0 (sin la enfermedad).
df_diag1: Casos con Diagnosis = 1 (con la enfermedad).
Verificación de datos: Se confirmó que ambas clases tuvieran al menos un dato antes de proceder.

Balanceo por undersampling:

Se redujo la clase mayoritaria (df_diag1) seleccionando aleatoriamente 801 registros, igualando la cantidad de la clase minoritaria.
Se combinaron ambas muestras en df_balanced, creando un conjunto equilibrado.
Verificación del balance: Se imprimió la tabla de frecuencias, confirmando que ahora ambas clases tienen 801 registros cada una.

Conclusión
El procedimiento ha sido exitoso, logrando que el dataset esté balanceado con la misma cantidad de ejemplos en cada categoría de Diagnosis. Esto ayudará a mejorar el desempeño de los modelos predictivos, evitando sesgos hacia la clase mayoritaria.
